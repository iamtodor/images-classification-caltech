{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "* http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "* https://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "* https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "* https://www.asozykin.ru/courses/nnpython\n",
    "* https://www.tensorflow.org/tutorials/deep_cnn#convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "img_channels = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), padding='same', kernel_initializer='he_uniform', \n",
    "           use_bias=False, input_shape=(img_width, img_height, img_channels)))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16665 images belonging to 256 classes.\n",
      "Found 5435 images belonging to 256 classes.\n",
      "Found 7680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "\n",
    "dir_train = 'data/keras/train'\n",
    "dir_val = 'data/keras/validation'\n",
    "dir_test = 'data/keras/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dir_val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    dir_test,\n",
    "    target_size=(img_width, img_height),\n",
    "    #class_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "120/120 [==============================] - 94s - loss: 5.1049 - acc: 0.0892 - val_loss: 4.9845 - val_acc: 0.0872\n",
      "Epoch 2/35\n",
      "120/120 [==============================] - 92s - loss: 4.6260 - acc: 0.1253 - val_loss: 4.6131 - val_acc: 0.1305\n",
      "Epoch 3/35\n",
      "120/120 [==============================] - 93s - loss: 4.4308 - acc: 0.1398 - val_loss: 4.4825 - val_acc: 0.1465\n",
      "Epoch 4/35\n",
      "120/120 [==============================] - 92s - loss: 4.2932 - acc: 0.1562 - val_loss: 4.3788 - val_acc: 0.1579\n",
      "Epoch 5/35\n",
      "120/120 [==============================] - 92s - loss: 4.1929 - acc: 0.1675 - val_loss: 4.3562 - val_acc: 0.1678\n",
      "Epoch 6/35\n",
      "120/120 [==============================] - 91s - loss: 4.1099 - acc: 0.1759 - val_loss: 4.4992 - val_acc: 0.1566\n",
      "Epoch 7/35\n",
      "120/120 [==============================] - 93s - loss: 4.0448 - acc: 0.1831 - val_loss: 4.2543 - val_acc: 0.1820\n",
      "Epoch 8/35\n",
      "120/120 [==============================] - 92s - loss: 3.9565 - acc: 0.1948 - val_loss: 4.3108 - val_acc: 0.1773\n",
      "Epoch 9/35\n",
      "120/120 [==============================] - 92s - loss: 3.9133 - acc: 0.1998 - val_loss: 4.2670 - val_acc: 0.1777\n",
      "Epoch 10/35\n",
      "120/120 [==============================] - 93s - loss: 3.8551 - acc: 0.2071 - val_loss: 4.1865 - val_acc: 0.1931\n",
      "Epoch 11/35\n",
      "120/120 [==============================] - 92s - loss: 3.8041 - acc: 0.2143 - val_loss: 4.1940 - val_acc: 0.1980\n",
      "Epoch 12/35\n",
      "120/120 [==============================] - 92s - loss: 3.7724 - acc: 0.2175 - val_loss: 4.1613 - val_acc: 0.1954\n",
      "Epoch 13/35\n",
      "120/120 [==============================] - 92s - loss: 3.7226 - acc: 0.2233 - val_loss: 4.2528 - val_acc: 0.1763\n",
      "Epoch 14/35\n",
      "120/120 [==============================] - 90s - loss: 3.6954 - acc: 0.2254 - val_loss: 4.3077 - val_acc: 0.1846\n",
      "Epoch 15/35\n",
      "120/120 [==============================] - 117s - loss: 3.6412 - acc: 0.2332 - val_loss: 4.1429 - val_acc: 0.2081\n",
      "Epoch 16/35\n",
      "120/120 [==============================] - 114s - loss: 3.6149 - acc: 0.2366 - val_loss: 4.2197 - val_acc: 0.1966\n",
      "Epoch 17/35\n",
      "120/120 [==============================] - 104s - loss: 3.5865 - acc: 0.2402 - val_loss: 4.1234 - val_acc: 0.2067\n",
      "Epoch 18/35\n",
      "120/120 [==============================] - 99s - loss: 3.5552 - acc: 0.2444 - val_loss: 4.1868 - val_acc: 0.2002\n",
      "Epoch 19/35\n",
      "120/120 [==============================] - 105s - loss: 3.5357 - acc: 0.2437 - val_loss: 4.1054 - val_acc: 0.2085\n",
      "Epoch 20/35\n",
      "120/120 [==============================] - 102s - loss: 3.4848 - acc: 0.2524 - val_loss: 4.1688 - val_acc: 0.2067\n",
      "Epoch 21/35\n",
      "120/120 [==============================] - 105s - loss: 3.4658 - acc: 0.2558 - val_loss: 4.1510 - val_acc: 0.2138\n",
      "Epoch 22/35\n",
      "120/120 [==============================] - 112s - loss: 3.4359 - acc: 0.2621 - val_loss: 4.1860 - val_acc: 0.2096\n",
      "Epoch 23/35\n",
      "120/120 [==============================] - 101s - loss: 3.4242 - acc: 0.2591 - val_loss: 4.1978 - val_acc: 0.2061\n",
      "Epoch 24/35\n",
      "120/120 [==============================] - 104s - loss: 3.3907 - acc: 0.2645 - val_loss: 4.1172 - val_acc: 0.2164\n",
      "Epoch 25/35\n",
      "120/120 [==============================] - 100s - loss: 3.3604 - acc: 0.2664 - val_loss: 4.0580 - val_acc: 0.2255\n",
      "Epoch 26/35\n",
      "120/120 [==============================] - 103s - loss: 3.3491 - acc: 0.2718 - val_loss: 4.1836 - val_acc: 0.2132\n",
      "Epoch 27/35\n",
      "120/120 [==============================] - 103s - loss: 3.3175 - acc: 0.2758 - val_loss: 4.1875 - val_acc: 0.2093\n",
      "Epoch 28/35\n",
      "120/120 [==============================] - 100s - loss: 3.3071 - acc: 0.2757 - val_loss: 4.1636 - val_acc: 0.2103\n",
      "Epoch 29/35\n",
      "120/120 [==============================] - 98s - loss: 3.2786 - acc: 0.2790 - val_loss: 4.5993 - val_acc: 0.1765\n",
      "Epoch 30/35\n",
      "120/120 [==============================] - 98s - loss: 3.2562 - acc: 0.2845 - val_loss: 4.1812 - val_acc: 0.2124\n",
      "Epoch 31/35\n",
      "120/120 [==============================] - 97s - loss: 3.2283 - acc: 0.2874 - val_loss: 4.1507 - val_acc: 0.2192\n",
      "Epoch 32/35\n",
      "120/120 [==============================] - 105s - loss: 3.2095 - acc: 0.2900 - val_loss: 4.1760 - val_acc: 0.2136\n",
      "Epoch 33/35\n",
      "120/120 [==============================] - 105s - loss: 3.1970 - acc: 0.2922 - val_loss: 4.1013 - val_acc: 0.2243\n",
      "Epoch 34/35\n",
      "120/120 [==============================] - 102s - loss: 3.1697 - acc: 0.2958 - val_loss: 4.2238 - val_acc: 0.2093\n",
      "Epoch 35/35\n",
      "120/120 [==============================] - 108s - loss: 3.1578 - acc: 0.2970 - val_loss: 4.1538 - val_acc: 0.2267\n",
      "CPU times: user 2h 46min 57s, sys: 23min 43s, total: 3h 10min 40s\n",
      "Wall time: 58min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=120,\n",
    "    epochs=35,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=20\n",
    ")\n",
    "\n",
    "model.save('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "model.fit(…, callbacks=[keras.callbacks.TensorBoard(log_dir='./logs')])\n",
    "keras + TensorBoard? callback keras.callbacks.TensorBoard(log_dir=‘./logs’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 16, 16, 16)        1200      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 16, 16, 16)        48        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 32)        4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 16, 16, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 32)        1024      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 16, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 512)               1536      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 4,334,752\n",
      "Trainable params: 4,333,568\n",
      "Non-trainable params: 1,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict_generator(test_generator, steps=300)\n",
    "results = np.argmax(results, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create submission dataframe (in specified kaggle format)\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip([i.split(\"/\")[1] for i in test_generator.filenames], results.astype(int).tolist())],\n",
    "    columns=['image', 'class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('keras_do-05.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folder = 'data/keras/train/test'\n",
    "\n",
    "files = ['11660.jpg', '12705.jpg', '13044.jpg', '14305.jpg', '14353.jpg', '14917.jpg',\n",
    " '16561.jpg', '18023.jpg', '18553.jpg', '18699.jpg', '18890.jpg', '19102.jpg',\n",
    " '2512.jpg', '25542.jpg', '25974.jpg', '2610.jpg', '2623.jpg', '26539.jpg',\n",
    " '27451.jpg', '28278.jpg', '28891.jpg', '29901.jpg', '31811.jpg', '3866.jpg',\n",
    " '5034.jpg', '5159.jpg', '5248.jpg', '5502.jpg', '5708.jpg', '7178.jpg']\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file in files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
