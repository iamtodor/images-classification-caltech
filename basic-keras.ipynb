{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "* http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "* https://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "* https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "* https://www.asozykin.ru/courses/nnpython\n",
    "* https://www.tensorflow.org/tutorials/deep_cnn#convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "img_channels = 3\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), padding='same', kernel_initializer='he_uniform', \n",
    "           use_bias=False, input_shape=(img_width, img_height, img_channels)))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16665 images belonging to 256 classes.\n",
      "Found 5435 images belonging to 256 classes.\n",
      "Found 7680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "\n",
    "dir_train = 'data/keras/train'\n",
    "dir_val = 'data/keras/validation'\n",
    "dir_test = 'data/keras/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dir_val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    dir_test,\n",
    "    target_size=(img_width, img_height),\n",
    "    #class_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "120/120 [==============================] - 110s - loss: 4.8960 - acc: 0.1089 - val_loss: 4.9993 - val_acc: 0.0802\n",
      "Epoch 2/35\n",
      "120/120 [==============================] - 95s - loss: 4.4189 - acc: 0.1494 - val_loss: 4.6648 - val_acc: 0.1143\n",
      "Epoch 3/35\n",
      "120/120 [==============================] - 100s - loss: 4.1862 - acc: 0.1716 - val_loss: 4.6136 - val_acc: 0.1279\n",
      "Epoch 4/35\n",
      "120/120 [==============================] - 98s - loss: 4.0509 - acc: 0.1901 - val_loss: 4.2225 - val_acc: 0.1842\n",
      "Epoch 5/35\n",
      "120/120 [==============================] - 104s - loss: 3.9370 - acc: 0.2007 - val_loss: 4.1872 - val_acc: 0.1840\n",
      "Epoch 6/35\n",
      "120/120 [==============================] - 101s - loss: 3.8494 - acc: 0.2133 - val_loss: 4.1642 - val_acc: 0.1957\n",
      "Epoch 7/35\n",
      "120/120 [==============================] - 97s - loss: 3.7597 - acc: 0.2230 - val_loss: 4.5669 - val_acc: 0.1585\n",
      "Epoch 8/35\n",
      "120/120 [==============================] - 97s - loss: 3.6927 - acc: 0.2288 - val_loss: 4.0651 - val_acc: 0.2120\n",
      "Epoch 9/35\n",
      "120/120 [==============================] - 100s - loss: 3.6359 - acc: 0.2378 - val_loss: 4.0943 - val_acc: 0.2071\n",
      "Epoch 10/35\n",
      "120/120 [==============================] - 99s - loss: 3.5728 - acc: 0.2497 - val_loss: 4.0799 - val_acc: 0.2120\n",
      "Epoch 11/35\n",
      "120/120 [==============================] - 98s - loss: 3.5207 - acc: 0.2539 - val_loss: 4.0758 - val_acc: 0.2073\n",
      "Epoch 12/35\n",
      "120/120 [==============================] - 97s - loss: 3.4593 - acc: 0.2622 - val_loss: 3.9895 - val_acc: 0.2272\n",
      "Epoch 13/35\n",
      "120/120 [==============================] - 95s - loss: 3.4210 - acc: 0.2670 - val_loss: 4.0772 - val_acc: 0.2146\n",
      "Epoch 14/35\n",
      "120/120 [==============================] - 102s - loss: 3.3695 - acc: 0.2739 - val_loss: 4.0450 - val_acc: 0.2225\n",
      "Epoch 15/35\n",
      "120/120 [==============================] - 102s - loss: 3.3329 - acc: 0.2770 - val_loss: 4.2956 - val_acc: 0.1976\n",
      "Epoch 16/35\n",
      "120/120 [==============================] - 95s - loss: 3.2817 - acc: 0.2856 - val_loss: 4.0166 - val_acc: 0.2298\n",
      "Epoch 17/35\n",
      "120/120 [==============================] - 111s - loss: 3.2351 - acc: 0.2924 - val_loss: 4.0285 - val_acc: 0.2276\n",
      "Epoch 18/35\n",
      "120/120 [==============================] - 102s - loss: 3.2164 - acc: 0.2976 - val_loss: 4.0795 - val_acc: 0.2255\n",
      "Epoch 19/35\n",
      "120/120 [==============================] - 98s - loss: 3.1753 - acc: 0.3010 - val_loss: 4.0475 - val_acc: 0.2261\n",
      "Epoch 20/35\n",
      "120/120 [==============================] - 96s - loss: 3.1358 - acc: 0.3065 - val_loss: 4.0042 - val_acc: 0.2379\n",
      "Epoch 21/35\n",
      "120/120 [==============================] - 96s - loss: 3.0956 - acc: 0.3129 - val_loss: 4.0329 - val_acc: 0.2314\n",
      "Epoch 22/35\n",
      "120/120 [==============================] - 96s - loss: 3.0674 - acc: 0.3151 - val_loss: 4.1487 - val_acc: 0.2204\n",
      "Epoch 23/35\n",
      "120/120 [==============================] - 100s - loss: 3.0345 - acc: 0.3197 - val_loss: 4.0367 - val_acc: 0.2304\n",
      "Epoch 24/35\n",
      "120/120 [==============================] - 97s - loss: 3.0111 - acc: 0.3272 - val_loss: 3.9894 - val_acc: 0.2458\n",
      "Epoch 25/35\n",
      "120/120 [==============================] - 97s - loss: 2.9665 - acc: 0.3338 - val_loss: 4.0551 - val_acc: 0.2381\n",
      "Epoch 26/35\n",
      "120/120 [==============================] - 97s - loss: 2.9285 - acc: 0.3409 - val_loss: 3.9379 - val_acc: 0.2478\n",
      "Epoch 27/35\n",
      "120/120 [==============================] - 98s - loss: 2.9230 - acc: 0.3395 - val_loss: 4.0086 - val_acc: 0.2478\n",
      "Epoch 28/35\n",
      "120/120 [==============================] - 100s - loss: 2.8866 - acc: 0.3462 - val_loss: 4.0315 - val_acc: 0.2436\n",
      "Epoch 29/35\n",
      "120/120 [==============================] - 100s - loss: 2.8729 - acc: 0.3452 - val_loss: 4.0290 - val_acc: 0.2426\n",
      "Epoch 30/35\n",
      "120/120 [==============================] - 100s - loss: 2.8277 - acc: 0.3572 - val_loss: 4.0482 - val_acc: 0.2385\n",
      "Epoch 31/35\n",
      "120/120 [==============================] - 100s - loss: 2.8047 - acc: 0.3611 - val_loss: 4.0414 - val_acc: 0.2440\n",
      "Epoch 32/35\n",
      "120/120 [==============================] - 107s - loss: 2.7896 - acc: 0.3633 - val_loss: 4.0740 - val_acc: 0.2365\n",
      "Epoch 33/35\n",
      "120/120 [==============================] - 110s - loss: 2.7539 - acc: 0.3682 - val_loss: 4.0934 - val_acc: 0.2446\n",
      "Epoch 34/35\n",
      "120/120 [==============================] - 102s - loss: 2.7360 - acc: 0.3706 - val_loss: 4.0050 - val_acc: 0.2488\n",
      "Epoch 35/35\n",
      "120/120 [==============================] - 102s - loss: 2.7073 - acc: 0.3743 - val_loss: 4.1073 - val_acc: 0.2349\n",
      "CPU times: user 2h 47min 7s, sys: 23min 56s, total: 3h 11min 4s\n",
      "Wall time: 58min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=120,\n",
    "    epochs=35,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=20\n",
    ")\n",
    "\n",
    "model.save('first_try.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "model.fit(…, callbacks=[keras.callbacks.TensorBoard(log_dir='./logs')])\n",
    "keras + TensorBoard? callback keras.callbacks.TensorBoard(log_dir=‘./logs’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict_generator(test_generator, steps=300)\n",
    "results = np.argmax(results, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create submission dataframe (in specified kaggle format)\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip([i.split(\"/\")[1] for i in test_generator.filenames], results.astype(int).tolist())],\n",
    "    columns=['image', 'class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('keras_do_02_best.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folder = 'data/keras/train/test'\n",
    "\n",
    "files = ['11660.jpg', '12705.jpg', '13044.jpg', '14305.jpg', '14353.jpg', '14917.jpg',\n",
    " '16561.jpg', '18023.jpg', '18553.jpg', '18699.jpg', '18890.jpg', '19102.jpg',\n",
    " '2512.jpg', '25542.jpg', '25974.jpg', '2610.jpg', '2623.jpg', '26539.jpg',\n",
    " '27451.jpg', '28278.jpg', '28891.jpg', '29901.jpg', '31811.jpg', '3866.jpg',\n",
    " '5034.jpg', '5159.jpg', '5248.jpg', '5502.jpg', '5708.jpg', '7178.jpg']\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file in files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
