{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "* http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "* https://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "* https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "* https://www.asozykin.ru/courses/nnpython\n",
    "* https://www.tensorflow.org/tutorials/deep_cnn#convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), padding='same', kernel_initializer='he_uniform', \n",
    "           use_bias=False, input_shape=(img_width, img_height, 3)))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16665 images belonging to 256 classes.\n",
      "Found 5435 images belonging to 256 classes.\n",
      "Found 7680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "\n",
    "dir_train = 'data/keras/train'\n",
    "dir_val = 'data/keras/validation'\n",
    "dir_test = 'data/keras/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dir_val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    dir_test,\n",
    "    target_size=(img_width, img_height),\n",
    "    #class_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo:\n",
    "model.fit(…, callbacks=[keras.callbacks.TensorBoard(log_dir='./logs')])\n",
    "keras + TensorBoard? callback keras.callbacks.TensorBoard(log_dir=‘./logs’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/22\n",
      "102/102 [==============================] - 47s - loss: 4.1038 - acc: 0.1745 - val_loss: 4.3415 - val_acc: 0.1658\n",
      "Epoch 2/22\n",
      "102/102 [==============================] - 40s - loss: 4.0841 - acc: 0.1786 - val_loss: 4.2982 - val_acc: 0.1768\n",
      "Epoch 3/22\n",
      "102/102 [==============================] - 47s - loss: 4.0637 - acc: 0.1788 - val_loss: 4.3745 - val_acc: 0.1528\n",
      "Epoch 4/22\n",
      "102/102 [==============================] - 48s - loss: 4.0382 - acc: 0.1803 - val_loss: 4.2448 - val_acc: 0.1777\n",
      "Epoch 5/22\n",
      "102/102 [==============================] - 46s - loss: 4.0293 - acc: 0.1821 - val_loss: 4.2658 - val_acc: 0.1722\n",
      "Epoch 6/22\n",
      "102/102 [==============================] - 46s - loss: 3.9999 - acc: 0.1838 - val_loss: 4.2570 - val_acc: 0.1726\n",
      "Epoch 7/22\n",
      "102/102 [==============================] - 43s - loss: 3.9599 - acc: 0.1879 - val_loss: 4.2858 - val_acc: 0.1698\n",
      "Epoch 8/22\n",
      "102/102 [==============================] - 50s - loss: 3.9792 - acc: 0.1854 - val_loss: 4.2855 - val_acc: 0.1703\n",
      "Epoch 9/22\n",
      "102/102 [==============================] - 47s - loss: 3.9441 - acc: 0.1893 - val_loss: 4.2579 - val_acc: 0.1763\n",
      "Epoch 10/22\n",
      "102/102 [==============================] - 39s - loss: 3.9473 - acc: 0.1883 - val_loss: 4.3124 - val_acc: 0.1716\n",
      "Epoch 11/22\n",
      "102/102 [==============================] - 41s - loss: 3.8999 - acc: 0.1965 - val_loss: 4.2441 - val_acc: 0.1880\n",
      "Epoch 12/22\n",
      "102/102 [==============================] - 43s - loss: 3.8960 - acc: 0.1989 - val_loss: 4.3001 - val_acc: 0.1635\n",
      "Epoch 13/22\n",
      "102/102 [==============================] - 41s - loss: 3.8968 - acc: 0.1951 - val_loss: 4.2830 - val_acc: 0.1785\n",
      "Epoch 14/22\n",
      "102/102 [==============================] - 41s - loss: 3.8855 - acc: 0.1969 - val_loss: 4.1811 - val_acc: 0.1875\n",
      "Epoch 15/22\n",
      "102/102 [==============================] - 40s - loss: 3.8472 - acc: 0.2016 - val_loss: 4.2669 - val_acc: 0.1857\n",
      "Epoch 16/22\n",
      "102/102 [==============================] - 42s - loss: 3.8505 - acc: 0.2001 - val_loss: 4.2091 - val_acc: 0.1862\n",
      "Epoch 17/22\n",
      "102/102 [==============================] - 41s - loss: 3.8206 - acc: 0.2043 - val_loss: 4.2343 - val_acc: 0.1858\n",
      "Epoch 18/22\n",
      "102/102 [==============================] - 44s - loss: 3.8201 - acc: 0.2019 - val_loss: 4.3130 - val_acc: 0.1815\n",
      "Epoch 19/22\n",
      "102/102 [==============================] - 40s - loss: 3.8100 - acc: 0.2073 - val_loss: 4.1675 - val_acc: 0.1956\n",
      "Epoch 20/22\n",
      "102/102 [==============================] - 42s - loss: 3.7929 - acc: 0.2059 - val_loss: 4.2946 - val_acc: 0.1797\n",
      "Epoch 21/22\n",
      "102/102 [==============================] - 43s - loss: 3.7854 - acc: 0.2043 - val_loss: 4.2512 - val_acc: 0.1817\n",
      "Epoch 22/22\n",
      "102/102 [==============================] - 42s - loss: 3.7511 - acc: 0.2114 - val_loss: 4.2614 - val_acc: 0.1776\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=102,\n",
    "    epochs=22,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=20\n",
    ")\n",
    "\n",
    "model.save('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict_generator(test_generator, steps=300)\n",
    "results = np.argmax(results, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create submission dataframe (in specified kaggle format)\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip([i.split(\"/\")[1] for i in test_generator.filenames], results.astype(int).tolist())],\n",
    "    columns=['image', 'class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('keras.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folder = 'data/keras/train/test'\n",
    "\n",
    "files = ['11660.jpg', '12705.jpg', '13044.jpg', '14305.jpg', '14353.jpg', '14917.jpg',\n",
    " '16561.jpg', '18023.jpg', '18553.jpg', '18699.jpg', '18890.jpg', '19102.jpg',\n",
    " '2512.jpg', '25542.jpg', '25974.jpg', '2610.jpg', '2623.jpg', '26539.jpg',\n",
    " '27451.jpg', '28278.jpg', '28891.jpg', '29901.jpg', '31811.jpg', '3866.jpg',\n",
    " '5034.jpg', '5159.jpg', '5248.jpg', '5502.jpg', '5708.jpg', '7178.jpg']\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file in files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
