{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "* http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "* https://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "* https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "* https://www.asozykin.ru/courses/nnpython\n",
    "* https://www.tensorflow.org/tutorials/deep_cnn#convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 32\n",
    "img_height = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (5, 5), strides=(2, 2), padding='same', kernel_initializer='he_uniform', \n",
    "           use_bias=False, input_shape=(img_width, img_height, 3)))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(32, (1, 1), padding='same', kernel_initializer='he_uniform', use_bias=False))\n",
    "model.add(BatchNormalization(scale=False))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, kernel_initializer='he_uniform'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16665 images belonging to 256 classes.\n",
      "Found 5435 images belonging to 256 classes.\n",
      "Found 7680 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "\n",
    "dir_train = 'data/keras/train'\n",
    "dir_val = 'data/keras/validation'\n",
    "dir_test = 'data/keras/test'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    dir_train,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    dir_val,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_generator = val_datagen.flow_from_directory(\n",
    "    dir_test,\n",
    "    target_size=(img_width, img_height),\n",
    "    #class_mode=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 42s - loss: 4.9947 - acc: 0.0942 - val_loss: 4.9060 - val_acc: 0.0895\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 45s - loss: 4.8343 - acc: 0.1064 - val_loss: 4.7605 - val_acc: 0.0980\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 54s - loss: 4.7081 - acc: 0.1134 - val_loss: 4.6595 - val_acc: 0.1168\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 53s - loss: 4.6433 - acc: 0.1175 - val_loss: 4.5906 - val_acc: 0.1240\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 61s - loss: 4.5782 - acc: 0.1266 - val_loss: 4.5657 - val_acc: 0.1225\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 54s - loss: 4.5035 - acc: 0.1308 - val_loss: 4.4844 - val_acc: 0.1286\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 43s - loss: 4.4460 - acc: 0.1372 - val_loss: 4.4154 - val_acc: 0.1405\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 42s - loss: 4.3941 - acc: 0.1448 - val_loss: 4.4471 - val_acc: 0.1455\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 45s - loss: 4.3762 - acc: 0.1437 - val_loss: 4.3412 - val_acc: 0.1510\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 46s - loss: 4.3367 - acc: 0.1520 - val_loss: 4.3368 - val_acc: 0.1531\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 47s - loss: 4.2963 - acc: 0.1520 - val_loss: 4.3630 - val_acc: 0.1585\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 41s - loss: 4.2707 - acc: 0.1596 - val_loss: 4.3387 - val_acc: 0.1588\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 46s - loss: 4.2431 - acc: 0.1611 - val_loss: 4.3902 - val_acc: 0.1568\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 49s - loss: 4.2101 - acc: 0.1626 - val_loss: 4.3995 - val_acc: 0.1570\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 42s - loss: 4.2057 - acc: 0.1613 - val_loss: 4.2436 - val_acc: 0.1698\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 43s - loss: 4.1809 - acc: 0.1684 - val_loss: 4.2908 - val_acc: 0.1684\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 43s - loss: 4.1377 - acc: 0.1722 - val_loss: 4.2939 - val_acc: 0.1680\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 40s - loss: 4.1493 - acc: 0.1694 - val_loss: 4.2977 - val_acc: 0.1671\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 41s - loss: 4.1255 - acc: 0.1739 - val_loss: 4.2588 - val_acc: 0.1671\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 42s - loss: 4.1004 - acc: 0.1745 - val_loss: 4.3282 - val_acc: 0.1661\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=20,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=20\n",
    ")\n",
    "\n",
    "model.save('first_try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = model.predict_generator(test_generator, steps=300)\n",
    "results = np.argmax(results, axis=1)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create submission dataframe (in specified kaggle format)\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip([i.split(\"/\")[1] for i in test_generator.filenames], results.astype(int).tolist())],\n",
    "    columns=['image', 'class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('keras.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import h5py\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "folder = 'data/keras/train/test'\n",
    "\n",
    "files = ['11660.jpg', '12705.jpg', '13044.jpg', '14305.jpg', '14353.jpg', '14917.jpg',\n",
    " '16561.jpg', '18023.jpg', '18553.jpg', '18699.jpg', '18890.jpg', '19102.jpg',\n",
    " '2512.jpg', '25542.jpg', '25974.jpg', '2610.jpg', '2623.jpg', '26539.jpg',\n",
    " '27451.jpg', '28278.jpg', '28891.jpg', '29901.jpg', '31811.jpg', '3866.jpg',\n",
    " '5034.jpg', '5159.jpg', '5248.jpg', '5502.jpg', '5708.jpg', '7178.jpg']\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if file in files:\n",
    "        file_path = os.path.join(folder, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            #elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
