{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* http://cs231n.github.io/neural-networks-2/#datapre\n",
    "* http://www.robots.ox.ac.uk/~vgg/practicals/cnn/#getting-started\n",
    "* https://www.safaribooksonline.com/library/view/programming-computer-vision/9781449341916/ch01.html\n",
    "* https://stackoverflow.com/a/10169025/5151861\n",
    "* augmentation tf+keras http://machinelearningmastery.com/image-augmentation-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation\n",
    "* rotation: random with angle between 0째 and 360째 (uniform)\n",
    "* translation: random with shift between -10 and 10 pixels (uniform)\n",
    "* rescaling: random with scale factor between 1/1.6 and 1.6 (log-uniform)\n",
    "* flipping: yes or no (bernoulli)\n",
    "* shearing: random with angle between -20째 and 20째 (uniform)\n",
    "* stretching: random with stretch factor between 1/1.3 and 1.3 (log-uniform)\n",
    "* whitening\n",
    "* https://www.tensorflow.org/api_docs/python/tf/image\n",
    "* https://github.com/aleju/imgaug\n",
    "* http://augmentor.readthedocs.io/en/master/\n",
    "* https://github.com/analysiscenter/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* uint8 0 to 255\n",
    "* uint16 0 to 65535\n",
    "* uint32 0 to 232\n",
    "* float -1 to 1 or 0 to 1\n",
    "* int8 -128 to 127\n",
    "* int16 -32768 to 32767\n",
    "* int32-231 to 231 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow\n",
    "import seaborn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/data_analys.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0/ 22897 images loaded\n",
      "  5000/ 22897 images loaded\n",
      " 10000/ 22897 images loaded\n",
      " 15000/ 22897 images loaded\n",
      " 20000/ 22897 images loaded\n",
      "CPU times: user 1min 16s, sys: 3.96 s, total: 1min 20s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dir_train_transformed = 'data/train_transformed'\n",
    "# img parameters\n",
    "img_shape = (64, 64)\n",
    "channels = 3\n",
    "img_shape_flattened = img_shape[0] * img_shape[1] * channels\n",
    "img_qty = train_df.shape[0]\n",
    "\n",
    "# initialize X,y\n",
    "X = np.empty(shape=(img_qty, img_shape_flattened), dtype=np.int8)\n",
    "y = np.empty(shape=(img_qty,), dtype=np.uint16)\n",
    "\n",
    "# read images\n",
    "for i,f_name in enumerate(os.listdir(dir_train_transformed)):\n",
    "    if i % 5000 == 0:\n",
    "        print('{:6d}/{:6d} images loaded'.format(i, img_qty))\n",
    "    \n",
    "    img_path = os.path.join(dir_train_transformed, f_name)\n",
    "    X[i, :] = misc.imread(img_path).flatten('C') # since img is np.ndarray, flatten in row-style\n",
    "    y[i] = train_df.loc[train_df['image_name'] == f_name, 'target'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11819607  0.15731014  0.18937642 ...,  0.94386439  0.94388505\n",
      "  0.94390567]\n",
      "CPU times: user 34min, sys: 1min 53s, total: 35min 53s\n",
      "Wall time: 15min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=5000).fit(X_train)\n",
    "print('{}'.format(np.cumsum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90169999999999995"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(np.cumsum(pca.explained_variance_ratio_)[-1400], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nICKSoxQARERy1P8H1gckxXr5af8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109982128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.xticks(np.arange(0, 5000, 500))\n",
    "plt.axhline(0.9, c='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=3600)\n",
    "\n",
    "X_train_sc = X_train / 255\n",
    "X_train_pca = pca.fit_transform(X_train_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_test_sc = X_test / 255\n",
    "X_test_pca = pca.transform(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(random_state=42, C=0.1, max_iter=50, verbose=2, n_jobs=-1, class_weight='balanced')\n",
    "reg.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(y_train, reg.predict(X_train_pca))\n",
    "accuracy(y_test, reg.predict(X_test_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    print('accuracy: {}'.format(accuracy_score(y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3600)\n",
    "svc = LogisticRegression(random_state=42, C=0.1, max_iter=50, verbose=2, n_jobs=-1, class_weight='balanced')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "model = Pipeline((('scaler', scaler), ('dim_reduction', pca), ('classifier', svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_df = pd.read_csv('data/data_analys.csv', index_col=0)\n",
    "dir_test_transformed = 'data/test_transformed'\n",
    "\n",
    "X_val = np.empty(shape=(img_qty, img_shape_flattened), dtype=np.int8)\n",
    "\n",
    "# read images\n",
    "for i,f_name in enumerate(os.listdir(dir_test_transformed)):\n",
    "    if i % 2000 == 0:\n",
    "        print('{} images loaded'.format(i))\n",
    "    \n",
    "    img_path = os.path.join(dir_test_transformed, f_name)\n",
    "    X_val[i, :] = misc.imread(img_path).flatten('C') # since img is np.ndarray, flatten in row-style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "X_test_pca = pca.transform(X_test)\n",
    "y_pred = svc.predict(X_test_pca)\n",
    "\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip(os.listdir(dir_test_transformed), y_pred.astype(int).tolist())],\n",
    "    columns=['image', 'class']\n",
    ")\n",
    "sub.to_csv('lr_baseline.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), data_format=\"channels_first\")`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(3, img_width, img_height)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), dim_ordering=\"th\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22897 images belonging to 257 classes.\n",
      "Found 0 images belonging to 0 classes.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_26_input to have shape (None, 3, 32, 32) but got array with shape (16, 32, 32, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-4e23a94adc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     validation_steps=nb_validation_samples // batch_size)\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'first_try.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1900\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1901\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1902\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1636\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1309\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1312\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1313\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_26_input to have shape (None, 3, 32, 32) but got array with shape (16, 32, 32, 3)"
     ]
    }
   ],
   "source": [
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/test'\n",
    "img_width = 32\n",
    "img_height = 32\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 800\n",
    "epochs = 50\n",
    "batch_size = 16\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save_weights('first_try.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
