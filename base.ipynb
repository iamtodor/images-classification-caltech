{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "* http://andrew.gibiansky.com/blog/machine-learning/convolutional-neural-networks/\n",
    "* http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/\n",
    "* https://medium.com/@ageitgey/machine-learning-is-fun-part-3-deep-learning-and-convolutional-neural-networks-f40359318721\n",
    "* https://algotravelling.com/ru/%D0%BC%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5-%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5-%D1%8D%D1%82%D0%BE-%D0%B2%D0%B5%D1%81%D0%B5%D0%BB%D0%BE-3/\n",
    "* https://adeshpande3.github.io/adeshpande3.github.io/A-Beginner's-Guide-To-Understanding-Convolutional-Neural-Networks-Part-2/\n",
    "* https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "* https://github.com/udsclub/images-classification-caltech\n",
    "* https://www.asozykin.ru/courses/nnpython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "* https://www.embedded-vision.com/sites/default/files/apress/computervisionmetrics/chapter2/9781430259299_Ch02.pdf\n",
    "* https://datascience.stackexchange.com/questions/5224/how-to-prepare-augment-images-for-neural-network\n",
    "* https://www.quora.com/What-are-some-ways-of-pre-procesing-images-before-applying-convolutional-neural-networks-for-the-task-of-image-classification\n",
    "* http://cs231n.github.io/neural-networks-2/#datapre\n",
    "* http://www.robots.ox.ac.uk/~vgg/practicals/cnn/#getting-started\n",
    "* https://www.safaribooksonline.com/library/view/programming-computer-vision/9781449341916/ch01.html\n",
    "* https://stackoverflow.com/a/10169025/5151861\n",
    "* augmentation tf+keras http://machinelearningmastery.com/image-augmentation-deep-learning-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augmentation\n",
    "* rotation: random with angle between 0° and 360° (uniform)\n",
    "* translation: random with shift between -10 and 10 pixels (uniform)\n",
    "* rescaling: random with scale factor between 1/1.6 and 1.6 (log-uniform)\n",
    "* flipping: yes or no (bernoulli)\n",
    "* shearing: random with angle between -20° and 20° (uniform)\n",
    "* stretching: random with stretch factor between 1/1.3 and 1.3 (log-uniform)\n",
    "* whitening\n",
    "* https://www.tensorflow.org/api_docs/python/tf/image\n",
    "* https://github.com/aleju/imgaug\n",
    "* http://augmentor.readthedocs.io/en/master/\n",
    "* https://github.com/analysiscenter/dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* uint8 0 to 255\n",
    "* uint16 0 to 65535\n",
    "* uint32 0 to 232\n",
    "* float -1 to 1 or 0 to 1\n",
    "* int8 -128 to 127\n",
    "* int16 -32768 to 32767\n",
    "* int32-231 to 231 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gaussian blurring of images\n",
    "* Morphology—Counting Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ресайзинг - важно\n",
    "* http://ufldl.stanford.edu/wiki/index.php/UFLDL_Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* одну- дву- слойную cnn\n",
    "* графики ошибки\n",
    "* 224х224\n",
    "* 32х32\n",
    "* в керас\n",
    "* серые картинки \n",
    "* тензор борд\n",
    "* презентация по аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0 # number of levels per pixel\n",
    "num_classes = 257 # number of total classes\n",
    "test_folder = 'data/test' # dir, where test set is placed\n",
    "train_folder = 'data/train' # dir, where train set is placed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape(img):\n",
    "    nsamples, nx, ny = img.shape\n",
    "    return img.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_set():\n",
    "    num_images = 0\n",
    "    images = os.listdir(test_folder)\n",
    "    test_set = []\n",
    "    for image in images:\n",
    "        image = os.path.join(test_folder, image)\n",
    "        test_set.append(io.imread(image))\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set = load_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "030.canoe\n",
      "060.duck\n",
      "090.gorilla\n",
      "120.joy-stick\n",
      "150.octopus\n",
      "180.screwdriver\n",
      "210.syringe\n",
      "240.watch-101\n",
      "CPU times: user 6min 2s, sys: 22.6 s, total: 6min 25s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dir_train = 'data/train'\n",
    "train_df = pd.DataFrame(columns = ['category', 'image_name', 'width', 'height', 'type', 'target'])\n",
    "folders = os.listdir(dir_train)\n",
    "for ind, folder in enumerate(folders):\n",
    "    if ind % 30 == 0:\n",
    "        print('{}'.format(folder))\n",
    "    folder = os.path.join(train_folder, folder)\n",
    "    if os.path.isdir(folder):\n",
    "        image_files = os.listdir(folder)\n",
    "        for image_file in image_files:\n",
    "            if not image_file.startswith('.'):\n",
    "                image = misc.imread(os.path.join(folder, image_file))\n",
    "                category = folder[15:]\n",
    "                width = image.shape[0]\n",
    "                height = image.shape[1]\n",
    "                #target = folder.split('.')[0].split('/')[2]\n",
    "                target = int(folder.split('.')[0].split('/')[2])\n",
    "                train_df.loc[train_df.shape[0]]=[category, image_file, width, \n",
    "                                                 height, image.dtype, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtcAAAHjCAYAAADojTN7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XuwZWdZJ+DfSxoQUAmXGDNJxkaNIuNIjEeNog4QUS6j\niVOCOI6kqIytNXG8To2NZalTpTVQo0ZxRsZIGDp4wYBgMiajxnjBuXDpQLhGKi0GkzYkLUJQUDH4\nzh9ntRybvuzu/tY5Z+/zPFWn9lrf+vY+7z5rr7V/Z+1vr1XdHQAA4PQ9aKsLAACAVSFcAwDAIMI1\nAAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMsmurCzgdj33sY3v37t1bXQYAACvu\n1ltv/fPuPutE/WYN11X1vUn+bZJO8vYkz09yTpJXJnlMkluTfGt3f7SqHprk2iRflOT9Sb6pu+88\n3uPv3r07+/fvn+8JAABAkqp67yL9ZhsWUlXnJvmuJGvd/flJzkjy3CQvSnJVd392kg8kuWK6yxVJ\nPjC1XzX1AwCApTH3mOtdSR5WVbuSPDzJPUmemuTV0/J9SS6bpi+d5jMtv6Sqaub6AABgmNnCdXcf\nTPITSf4066H6/qwPA/lgdz8wdbs7ybnT9LlJ7pru+8DU/zFHPm5V7amq/VW1/9ChQ3OVDwAAJ23O\nYSGPyvrR6Mcl+SdJHpHk6af7uN19dXevdffaWWedcEw5AABsmjmHhXx1kj/p7kPd/XdJXpPkSUnO\nnIaJJMl5SQ5O0weTnJ8k0/JHZv2LjQAAsBTmDNd/muTiqnr4NHb6kiTvSvJ7Sb5x6nN5kuun6Rum\n+UzLf7e7e8b6AABgqDnHXL8h619MfHPWT8P3oCRXJ/mBJN9XVQeyPqb6muku1yR5zNT+fUn2zlUb\nAADMoZb54PDa2lo7zzUAAHOrqlu7e+1E/Vz+HAAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEA\nYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAbZtdUFAACwM+3ee+M/TN/5wmdtYSXjCNcAbCur\n+GYL7ByGhQAAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1\nAAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAA\nDCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwi\nXAMAwCDCNQAADDJbuK6qz62q2zb8fKiqvqeqHl1VN1fVHdPto6b+VVUvrqoDVfW2qrportoAAGAO\ns4Xr7n53d1/Y3Rcm+aIkH0ny2iR7k9zS3RckuWWaT5JnJLlg+tmT5CVz1QYAAHPYrGEhlyT54+5+\nb5JLk+yb2vcluWyavjTJtb3u9UnOrKpzNqk+AAA4bZsVrp+b5Fem6bO7+55p+n1Jzp6mz01y14b7\n3D21/SNVtaeq9lfV/kOHDs1VLwAAnLTZw3VVPSTJ1yd51ZHLuruT9Mk8Xndf3d1r3b121llnDaoS\nAABO32YcuX5Gkjd3973T/L2Hh3tMt/dN7QeTnL/hfudNbQAAsBQ2I1x/cz4+JCRJbkhy+TR9eZLr\nN7Q/bzpryMVJ7t8wfAQAALa9XXM+eFU9IsnTknz7huYXJrmuqq5I8t4kz5nab0ryzCQHsn5mkefP\nWRsAAIw2a7ju7g8necwRbe/P+tlDjuzbSa6csx4AAJiTKzQCAMAgwjUAAAwiXAMAwCDCNQAADCJc\nAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMA\nwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAg\nwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1\nAAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCCzhuuq\nOrOqXl1Vf1RVt1fVl1XVo6vq5qq6Y7p91NS3qurFVXWgqt5WVRfNWRsAAIw295Hrn0nym939+CRP\nTHJ7kr1JbunuC5LcMs0nyTOSXDD97EnykplrAwCAoWYL11X1yCRfleSaJOnuj3b3B5NcmmTf1G1f\nksum6UuTXNvrXp/kzKo6Z676AABgtDmPXD8uyaEk/6Oq3lJVL62qRyQ5u7vvmfq8L8nZ0/S5Se7a\ncP+7p7Z/pKr2VNX+qtp/6NChGcsHAICTM2e43pXkoiQv6e4vTPLhfHwISJKkuztJn8yDdvfV3b3W\n3WtnnXXWsGIBAOB0zRmu705yd3e/YZp/ddbD9r2Hh3tMt/dNyw8mOX/D/c+b2gAAYCnMFq67+31J\n7qqqz52aLknyriQ3JLl8ars8yfXT9A1JnjedNeTiJPdvGD4CAADb3q6ZH//fJ/mlqnpIkvckeX7W\nA/11VXVFkvcmec7U96Ykz0xyIMlHpr4AALA0Zg3X3X1bkrWjLLrkKH07yZVz1gMAAHNyhUYAABhE\nuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgG\nAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCA\nQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGE\nawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAABhEuAYAgEGEawAAGES4BgCAQYRrAAAYRLgGAIBBhGsA\nABhEuAYAgEGEawAAGGTWcF1Vd1bV26vqtqraP7U9uqpurqo7pttHTe1VVS+uqgNV9baqumjO2gAA\nYLTNOHL9lO6+sLvXpvm9SW7p7guS3DLNJ8kzklww/exJ8pJNqA0AAIbZimEhlybZN03vS3LZhvZr\ne93rk5xZVedsQX0AAHBK5g7XneS3q+rWqtoztZ3d3fdM0+9LcvY0fW6Suzbc9+6p7R+pqj1Vtb+q\n9h86dGiuugEA4KTtmvnxv6K7D1bVpyW5uar+aOPC7u6q6pN5wO6+OsnVSbK2tnZS9wUAgDnNeuS6\nuw9Ot/cleW2SL0ly7+HhHtPtfVP3g0nO33D386Y2AABYCrOF66p6RFV9yuHpJF+T5B1Jbkhy+dTt\n8iTXT9M3JHnedNaQi5Pcv2H4CAAAbHtzDgs5O8lrq+rw7/nl7v7NqnpTkuuq6ook703ynKn/TUme\nmeRAko8kef6MtQEAwHCzhevufk+SJx6l/f1JLjlKeye5cq56AABgbq7QCAAAgwjXAAAwiHANAACD\nCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjX\nAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACDLBSuq+qfz10IAAAsu0WP\nXP9cVb2xqv5dVT1y1ooAAGBJLRSuu/srk3xLkvOT3FpVv1xVT5u1MgAAWDILj7nu7juS/FCSH0jy\nL5K8uKr+qKr+1VzFAQDAMll0zPUXVNVVSW5P8tQkX9fdnzdNXzVjfQAAsDR2LdjvZ5O8NMkPdvdf\nH27s7j+rqh+apTIAAFgyi4brZyX56+7+WJJU1YOSfFJ3f6S7XzFbdQAAsEQWHXP9O0ketmH+4VMb\nAAAwWTRcf1J3/9XhmWn64fOUBAAAy2nRcP3hqrro8ExVfVGSvz5OfwAA2HEWHXP9PUleVVV/lqSS\nfHqSb5qtKgAAWEILhevuflNVPT7J505N7+7uv5uvLAAAWD6LHrlOki9Osnu6z0VVle6+dpaqAABg\nCS0UrqvqFUk+K8ltST42NXcS4RoAACaLHrleS/KE7u45iwEAgGW26NlC3pH1LzECAADHsOiR68cm\neVdVvTHJ3x5u7O6vn6UqAABYQouG6x+dswgAAFgFi56K7w+q6jOSXNDdv1NVD09yxrylAQDAcllo\nzHVVfVuSVyf5+anp3CS/PldRAACwjBb9QuOVSZ6U5ENJ0t13JPm0uYoCAIBltGi4/tvu/ujhmara\nlfXzXAMAAJNFw/UfVNUPJnlYVT0tyauS/M/5ygIAgOWzaLjem+RQkrcn+fYkNyX5oUXuWFVnVNVb\nquo3pvnHVdUbqupAVf1qVT1kan/oNH9gWr77ZJ8MAABspYXCdXf/fXf/Qnc/u7u/cZpedFjIdye5\nfcP8i5Jc1d2fneQDSa6Y2q9I8oGp/aqpHwAAO8juvTdm994bt7qMU7bo2UL+pKrec+TPAvc7L8mz\nkrx0mq8kT836mUeSZF+Sy6bpS6f5TMsvmfoDAMBSWPQiMmsbpj8pybOTPHqB+/10kv+Y5FOm+cck\n+WB3PzDN35310/plur0rSbr7gaq6f+r/5wvWCAAAW2rRYSHv3/BzsLt/OutHpI+pqv5lkvu6+9YR\nhW543D1Vtb+q9h86dGjkQwMAwGlZ6Mh1VV20YfZBWT+SfaL7PinJ11fVM7N+tPtTk/xMkjOratd0\n9Pq8JAen/geTnJ/k7ulUf49M8v4jH7S7r05ydZKsra05HSAAANvGosNCfnLD9ANJ7kzynOPdobtf\nkOQFSVJVT07yH7r7W6rqVUm+Mckrk1ye5PrpLjdM8/9vWv67J/GlSQAA2HILhevufsrA3/kDSV5Z\nVT+W5C1Jrpnar0nyiqo6kOQvkjx34O8EAIDZLTos5PuOt7y7f+oEy38/ye9P0+9J8iVH6fM3Wf+i\nJAAALKWTOVvIF2d96EaSfF2SNya5Y46iAABgGS0ars9LclF3/2WSVNWPJrmxu//NXIUBAMCyWfTy\n52cn+eiG+Y9ObQAAwGTRI9fXJnljVb12mr8sH7+aIgAAkMXPFvLjVfW/knzl1PT87n7LfGUBAMDy\nWXRYSJI8PMmHuvtnsn6hl8fNVBMAACylhcJ1Vf1I1s9P/YKp6cFJfnGuogAAYBkteuT6G5J8fZIP\nJ0l3/1mST5mrKAAAWEaLhuuPTpci7ySpqkfMVxIAACynRcP1dVX180nOrKpvS/I7SX5hvrIAAGD5\nLHq2kJ+oqqcl+VCSz03yw91986yVAQDAkjlhuK6qM5L8Tnc/JYlADQAAx3DCYSHd/bEkf19Vj9yE\negAAYGkteoXGv0ry9qq6OdMZQ5Kku79rlqoAAGAJLRquXzP9AAAAx3DccF1V/7S7/7S7921WQQAA\nsKxONOb61w9PVNWvzVwLAAAstROF69ow/ZlzFgIAAMvuROG6jzENAAAc4URfaHxiVX0o60ewHzZN\nZ5rv7v7UWasDAIAlctxw3d1nbFYhAACw7E54ERkAAGAxwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1\nAAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMsmurCwAA4PTt3nvjP0zf+cJnbWEl\nO5sj1wAAMIhwDQAAgwjXAAAwiHANAACDCNcAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANAACD\nCNcAADDIbOG6qj6pqt5YVW+tqndW1X+a2h9XVW+oqgNV9atV9ZCp/aHT/IFp+e65agMAgDnMeeT6\nb5M8tbufmOTCJE+vqouTvCjJVd392Uk+kOSKqf8VST4wtV819QMAgKUxW7judX81zT54+ukkT03y\n6ql9X5LLpulLp/lMyy+pqpqrPgAAGG3WMddVdUZV3ZbkviQ3J/njJB/s7gemLncnOXeaPjfJXUky\nLb8/yWOO8ph7qmp/Ve0/dOjQnOUDAMBJmTVcd/fHuvvCJOcl+ZIkjx/wmFd391p3r5111lmnXSMA\nAIyyKWcL6e4PJvm9JF+W5Myq2jUtOi/JwWn6YJLzk2Ra/sgk79+M+gAAYIQ5zxZyVlWdOU0/LMnT\nktye9ZD9jVO3y5NcP03fMM1nWv673d1z1QcAAKPtOnGXU3ZOkn1VdUbWQ/x13f0bVfWuJK+sqh9L\n8pYk10z9r0nyiqo6kOQvkjx3xtoAAGC42cJ1d78tyRcepf09WR9/fWT73yR59lz1AADA3FyhEQAA\nBhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYR\nrgEAYBDhGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGugaW3e++N2b33xq0u\nAwCEawAAGEW4BgCAQYTrbc7H3QAAy0O4BgCAQYRrAAAYRLgGAIBBhGsAABhk11YXALAdbfwi8Z0v\nfNYWVgLAMnHkGgAABhGuAQBgEOEaAAAGEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaAAAG\nEa4BAGAQ4RoAAAYRrgEAYBDhGgAABhGuAQBgEOEaYIXt3ntjdu+9cavLANgxhGsAABhEuAYAgEFm\nC9dVdX5V/V5Vvauq3llV3z21P7qqbq6qO6bbR03tVVUvrqoDVfW2qrportoAAGAOcx65fiDJ93f3\nE5JcnOTKqnpCkr1JbunuC5LcMs0nyTOSXDD97EnykhlrAwCA4WYL1919T3e/eZr+yyS3Jzk3yaVJ\n9k3d9iW5bJq+NMm1ve71Sc6sqnPmqm878YUjAIDVsCljrqtqd5IvTPKGJGd39z3TovclOXuaPjfJ\nXRvudvfUduRj7amq/VW1/9ChQ7PVDAAAJ2v2cF1Vn5zk15J8T3d/aOOy7u4kfTKP191Xd/dad6+d\nddZZAysFAIDTM2u4rqoHZz1Y/1J3v2ZqvvfwcI/p9r6p/WCS8zfc/bypDQAAlsKcZwupJNckub27\nf2rDohuSXD5NX57k+g3tz5vOGnJxkvs3DB8BAIBtb9eMj/2kJN+a5O1VddvU9oNJXpjkuqq6Isl7\nkzxnWnZTkmcmOZDkI0meP2NtAAAw3Gzhurv/d5I6xuJLjtK/k1w5Vz0AADA3V2gEAIBBhGsAABhE\nuF4SLjQDALD9CdcAADCIcA1sGz6hAWDZCdcAADCIcA0AR+GTFOBUCNcAADCIcA0AAIMI1wBse4Zo\nAMtitsufA5yujWHqzhc+awsrAdhZ7H9PnSPXAAAwiHANAACDCNcAADCIcA0AAIMI1wAM5cwewE7m\nbCEAO9TxzgbgTAEAp8aRawAAGES4BgCAQYRrAAAYRLgGAIBBhGsAALa1ZToLkXANAACDCNcAADCI\n81wDsDScf3t5WFfsVI5cAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAM\nIlwDAMAgrtAIcBoOX4Vup1+BbuPV+AB2MkeuAQBgEOEaAAAGEa5nsHvvjT4iBQDYgYy53gQbg/ZO\nH5cJsJ05MAKcLuEaAGAbcnBuORkWAgAAgwjXAAAwiGEhO5iPmwAAxhKuAWCTuOjQ8nEgipNlWAiw\n4zhdJgBzmS1cV9XLquq+qnrHhrZHV9XNVXXHdPuoqb2q6sVVdaCq3lZVF81VFwAnxz8j7CRe75yu\nOY9cvzzJ049o25vklu6+IMkt03ySPCPJBdPPniQvmbEudig7TABgbrOF6+5+XZK/OKL50iT7pul9\nSS7b0H5tr3t9kjOr6py5aoPtzj8CALCcNnvM9dndfc80/b4kZ0/T5ya5a0O/u6e2T1BVe6pqf1Xt\nP3To0HyVAmwjq/wP1yo/N2Dn2bKzhXR3V1Wfwv2uTnJ1kqytrZ30/QF2Imc8ANgcmx2u762qc7r7\nnmnYx31T+8Ek52/od97UttQciQEA2Fk2e1jIDUkun6YvT3L9hvbnTWcNuTjJ/RuGjzDIqnz0erzn\nsSrPEQBYTrMdua6qX0ny5CSPraq7k/xIkhcmua6qrkjy3iTPmbrflOSZSQ4k+UiS589V1yryce9q\n8E8BAKO5cNHmmy1cd/c3H2PRJUfp20munKsWlsuIfxb8w8F2dbw3Om+C4/hbHpv9I8zL5c/hFCzT\nG/cy1cr2JpRxmP0KHJvLnwOwaXwvAlh1jlzDDnM6Rx8drTo1wiRsHfut5bEq+0rhmhPaqTumnfq8\nAVg9hnVtHuGaY1qV/yDZOiP/QZnzn51lf9PZ6f8ILvv6W2aLvk9s19fodq3rZHm/3l6Ea/6Rk91A\n594xrcqObw6rEii8KTDSTno92T+enO3691qVfTkfJ1wDbKGjhcHtGgJG2kkhmMUImawK4XqLLOMb\ny9w7vq38myzL8AUYYRn3P3Pbrn+Tnbo/WabnvUy1sjmcim9FbeXprpxqizl5fcFqsC2zqhy53kaW\n+b/fZf1Sy8gd+3Ybr87q2+nBZLO3ubk+vdtO313ZCUMztmK7sb/fWYTrFTfXTuRU39SONm9nc2xz\nDFfZKXb6m9lOW99bbRn2adt1fP/xXqtbWd+yb0Nb+en1YUdbb9vhNTc34fo0bfaLZBl24DvJdtn5\nHvk63Moj8lv9uLAKTnX72AnBZRFz71+W/fGZl3A9yLJvCMte/yj+DngN7Byrsq5X5Xksyj8Qp+94\nB2S24mDhqhGut6FVfsFtB/6+p+9ob26GsMBq2gmfmC7DJ3SrckatU/m9y0a4hpks6xvSZl0JcbMt\n6056s53sl5O3u+ONM97M333k9rQsfz/Y6GTfH3bqpwzC9Yqxw4ad63S2f/uOk7NTQ8N2sowHMJax\n5hOx7/hEwvUm20kvwp30XFfRMq6/zfqS0aq8KW6WZXwtLWqVnxubb7NfT6f7xVmOTrhmy+2kjXsZ\na15lWzkEYpHH9HpZTqu83k73uTnLBjuBcL3EdtJOZCs/7l7Fj/FWwXYbv+2o9ifaSfuoE/G3gJ1D\nuN6B7OQ33yIXSTjV+59Kv1Ptv1WPuUx2+vNfRVvxBcjNrsHrdjE74RMn7wunT7iGk7DTdhAn4u+x\n+Vb5b76VZ/bgE22nv/12quVYlqFGNkd191bXcMrW1tZ6//79W1qDjQkAYHNs5dC7qrq1u9dO1O9B\nm1EMAADsBMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwi\nXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwDAMAgwjUAAAwiXAMAwCDCNQAADCJcAwDAIMI1AAAMIlwD\nAMAgwjUAAAwiXAMAwCDbKlxX1dOr6t1VdaCq9m51PQAAcDK2TbiuqjOS/Lckz0jyhCTfXFVP2Nqq\nAABgcdsmXCf5kiQHuvs93f3RJK9McukW1wQAAAvbtdUFbHBukrs2zN+d5EuP7FRVe5LsmWb/qqre\nvQm1Hc1jk/z5Fv1u5mO9ri7rdnVZt6vLul1dp7Ru60UzVLK4z1ik03YK1wvp7quTXL3VdVTV/u5e\n2+o6GMt6XV3W7eqybleXdbu6VnndbqdhIQeTnL9h/rypDQAAlsJ2CtdvSnJBVT2uqh6S5LlJbtji\nmgAAYGHbZlhIdz9QVd+Z5LeSnJHkZd39zi0u63i2fGgKs7BeV5d1u7qs29Vl3a6ulV231d1bXQMA\nAKyE7TQsBAAAlppwDQAAgwjXJ8kl2ldLVd1ZVW+vqtuqav/U9uiqurmq7phuH7XVdXJiVfWyqrqv\nqt6xoe2o67LWvXjajt9WVRdtXeWcyDHW7Y9W1cFp272tqp65YdkLpnX77qr62q2pmhOpqvOr6veq\n6l1V9c6q+u6p3Xa75I6zbnfEditcnwSXaF9ZT+nuCzecb3Nvklu6+4Ikt0zzbH8vT/L0I9qOtS6f\nkeSC6WdPkpdsUo2cmpfnE9dtklw1bbsXdvdNSTLtk5+b5J9N9/m5ad/N9vNAku/v7ickuTjJldP6\ns90uv2Ot22QHbLfC9clxifad4dIk+6bpfUku28JaWFB3vy7JXxzRfKx1eWmSa3vd65OcWVXnbE6l\nnKxjrNtjuTTJK7v7b7v7T5IcyPq+m22mu+/p7jdP03+Z5PasX63ZdrvkjrNuj2Wltlvh+uQc7RLt\nx3uxsP11kt+uqluras/UdnZ33zNNvy/J2VtTGgMca13allfDd07DA162YfiWdbuEqmp3ki9M8obY\nblfKEes22QHbrXDNTvcV3X1R1j9uvLKqvmrjwl4/V6XzVa4A63LlvCTJZyW5MMk9SX5ya8vhVFXV\nJyf5tSTf090f2rjMdrvcjrJud8R2K1yfHJdoXzHdfXC6vS/Ja7P+MdS9hz9qnG7v27oKOU3HWpe2\n5SXX3fd298e6+++T/EI+/hGydbtEqurBWQ9fv9Tdr5mabbcr4Gjrdqdst8L1yXGJ9hVSVY+oqk85\nPJ3ka5K8I+vr9PKp2+VJrt+aChngWOvyhiTPm84+cHGS+zd8DM0SOGKs7TdkfdtN1tftc6vqoVX1\nuKx/+e2Nm10fJ1ZVleSaJLd3909tWGS7XXLHWrc7ZbvdNpc/XwZLeIl2ju/sJK9d3wdkV5Jf7u7f\nrKo3Jbmuqq5I8t4kz9nCGllQVf1KkicneWxV3Z3kR5K8MEdflzcleWbWvzTzkSTP3/SCWdgx1u2T\nq+rCrA8ZuDPJtydJd7+zqq5L8q6sn7Hgyu7+2FbUzQk9Kcm3Jnl7Vd02tf1gbLer4Fjr9pt3wnbr\n8ucAADCIYSEAADCIcA0AAIMI1wAAMIhwDQAAgwjXAAAwiHANsESq6tOr6pVV9cdVdWtV3VRVn1NV\n7zjxvQGYm/NcAyyJ6cIMr02yr7ufO7U9MevnbAdgG3DkGmB5PCXJ33X3fz/c0N1vTXLX4fmq2l1V\nf1hVb55+vnxqP6eqXldVt1XVO6rqK6vqjKp6+TT/9qr63qnvZ1XVb05Hxv+wqh4/tT976vvWqnrd\n5j51gOXgyDXA8vj8JLeeoM99SZ7W3X9TVRck+ZUka0n+dZLf6u4fr6ozkjw8yYVJzu3uz0+Sqjpz\neoyrk3x5akFDAAABmUlEQVRHd99RVV+a5OeSPDXJDyf52u4+uKEvABsI1wCr5cFJ/ut0ieGPJfmc\nqf1NSV5WVQ9O8uvdfVtVvSfJZ1bVzya5MclvV9UnJ/nyJK9aH4WSJHnodPt/krx8ukzxazbn6QAs\nF8NCAJbHO5N80Qn6fG+Se5M8MetHrB+SJN39uiRfleRg1gPy87r7A1O/30/yHUlemvX3hQ9294Ub\nfj5veozvSPJDSc5PcmtVPWbw8wNYesI1wPL43SQPrao9hxuq6guyHnYPe2SSe7r775N8a5Izpn6f\nkeTe7v6FrIfoi6rqsUke1N2/lvXQfFF3fyjJn1TVs6f71fSlyVTVZ3X3G7r7h5McOuL3AhDhGmBp\ndHcn+YYkXz2diu+dSf5zkvdt6PZzSS6vqrcmeXySD0/tT07y1qp6S5JvSvIzSc5N8vtVdVuSX0zy\ngqnvtyS5YnqMdya5dGr/L9MXH9+R5P8mees8zxRgedX6vhoAADhdjlwDAMAgwjUAAAwiXAMAwCDC\nNQAADCJcAwDAIMI1AAAMIlwDAMAg/x/Pyy2wDo5pOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114aaba20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.hist(train_df['target'], bins=range(len(train_df['target'].unique())))\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_df.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']\n",
    "X = train_df.copy()\n",
    "X.drop('target', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.to_csv('data/train_features')\n",
    "y.to_csv('data/train_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        create_dir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dir(directory):\n",
    "    os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(img):\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "030.canoe\n",
      "060.duck\n",
      "090.gorilla\n",
      "120.joy-stick\n",
      "150.octopus\n",
      "180.screwdriver\n",
      "210.syringe\n",
      "240.watch-101\n"
     ]
    }
   ],
   "source": [
    "dir_train_transformed = 'data/train_transformed'\n",
    "dir_train = 'data/train'\n",
    "img_size=(64, 64)\n",
    "    \n",
    "check_dir(dir_train_transformed)\n",
    "folders = os.listdir(dir_train)\n",
    "for ind, folder in enumerate(folders):\n",
    "        subfolder = os.path.join(dir_train, folder)\n",
    "        if os.path.isdir(subfolder):\n",
    "            if ind % 30 == 0:\n",
    "                print('{}'.format(folder))\n",
    "            for image_file in os.listdir(subfolder):\n",
    "                if not image_file.startswith('.'):\n",
    "                    name = os.path.join(subfolder, image_file)\n",
    "                    image = misc.imread(name)\n",
    "                    if len(image.shape) == 2:\n",
    "                        image = np.stack((image,)*3)\n",
    "                    image = misc.imresize(image, img_size, interp='bicubic')\n",
    "                    #image = norm(image)\n",
    "                    fold_to_save = os.path.join(dir_train_transformed, image_file)\n",
    "                    misc.imsave(fold_to_save, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0/ 22897 images loaded\n",
      "  5000/ 22897 images loaded\n",
      " 10000/ 22897 images loaded\n",
      " 15000/ 22897 images loaded\n",
      " 20000/ 22897 images loaded\n",
      "CPU times: user 1min 15s, sys: 3.99 s, total: 1min 19s\n",
      "Wall time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load data in flattened form\n",
    "\n",
    "dir_train_transformed = 'data/train_transformed'\n",
    "# img parameters\n",
    "img_shape = (64, 64)\n",
    "channels = 3\n",
    "img_shape_flattened = img_shape[0] * img_shape[1] * channels\n",
    "img_qty = train_df.shape[0]\n",
    "\n",
    "# initialize X,y\n",
    "X = np.empty(shape=(img_qty, img_shape_flattened), dtype=np.int8)\n",
    "y = np.empty(shape=(img_qty,), dtype=np.uint16)\n",
    "\n",
    "# read images\n",
    "for i,f_name in enumerate(os.listdir(dir_train_transformed)):\n",
    "    if i % 5000 == 0:\n",
    "        print('{:6d}/{:6d} images loaded'.format(i, img_qty))\n",
    "    \n",
    "    img_path = os.path.join(dir_train_transformed, f_name)\n",
    "    X[i, :] = misc.imread(img_path).flatten('C') # since img is np.ndarray, flatten in row-style\n",
    "    y[i] = train_df.loc[train_df['image_name'] == f_name, 'target'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, t_test = train_test_split(X, y, test_size = 0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression  # baseline classifier\n",
    "from sklearn.decomposition import PCA # to reduce training columns\n",
    "from sklearn.pipeline import Pipeline # to \"glue\" model steps/components together\n",
    "from sklearn.metrics import accuracy_score # to test quality of the classifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find optimal PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000).fit(X_train)\n",
    "print('{}'.format(np.cumsum(pca.explained_variance_ratio_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Total explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2000, random_state=42)\n",
    "svc = LogisticRegression(random_state=42, C=0.1, max_iter=50, verbose=2, n_jobs=-1, class_weight='balanced')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "model = Pipeline((('scaler', scaler), ('dim_reduction', pca), ('classifier', svc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy(X_train, y_train)\n",
    "accuracy(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "sub = pd.DataFrame(\n",
    "    data=[row for row in zip(os.list.dir(dir_test_transformed), y_pred.astype(int).tolist)],\n",
    "    columns=['image', 'class']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, y):\n",
    "    print('accuracy: {}'.forma(accuracy_score(y, model.predict(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_test_transformed = 'data/test_transformed'\n",
    "img_size=(64, 64)\n",
    "check_dir(dir_test_transformed)\n",
    "folders = os.listdir(dir_test_transformed)\n",
    "for ind, folder in enumerate(folders):\n",
    "        subfolder = os.path.join(train_folder, folder)\n",
    "        if os.path.isdir(subfolder):\n",
    "            if ind % 30 == 0:\n",
    "                print('{}'.format(folder))\n",
    "            for image_file in os.listdir(subfolder):\n",
    "                if not image_file.startswith('.'):\n",
    "                    name = os.path.join(subfolder, image_file)\n",
    "                    image = misc.imread(name)\n",
    "                    if len(image.shape) == 2:\n",
    "                        image = np.stack((image,)*3)\n",
    "                    image = misc.imresize(image, img_size, interp='bicubic')\n",
    "                    #image = norm(image)\n",
    "                    fold_to_save = os.path.join(transform_folder, image_file)\n",
    "                    misc.imsave(fold_to_save, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load data in flattened form\n",
    "\n",
    "# img parameters\n",
    "dir_test_transformed = 'data/test_transformed'\n",
    "img_shape_flattened = img_shape[0] * img_shape[1] * channels\n",
    "img_qty = train_df.shape[0]\n",
    "\n",
    "# initialize X,y\n",
    "X_test = np.empty(shape=(img_qty, img_shape_flattened), dtype=np.int8)\n",
    "\n",
    "# read images\n",
    "for i,f_name in enumerate(os.listdir(dir_test_transformed)):\n",
    "    if i % 5000 == 0:\n",
    "        print('{:6d}/{:6d} images loaded'.format(i, img_qty))\n",
    "    \n",
    "    img_path = os.path.join(dir_train_transformed, f_name)\n",
    "    X[i, :] = misc.imread(img_path).flatten('C') # since img is np.ndarray, flatten in row-style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
